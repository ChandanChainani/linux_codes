{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arch/x86/include/asm/barrier.h\n",
    "\n",
    "```c\n",
    "/*\n",
    " * Force strict CPU ordering.\n",
    " * And yes, this is required on UP too when we're talking\n",
    " * to devices.\n",
    " */\n",
    "\n",
    "#ifdef CONFIG_X86_32\n",
    "/*\n",
    " * Some non-Intel clones support out of order store. wmb() ceases to be a\n",
    " * nop for these.\n",
    " */\n",
    "#define mb() alternative(\"lock; addl $0,0(%%esp)\", \"mfence\", X86_FEATURE_XMM2)\n",
    "#define rmb() alternative(\"lock; addl $0,0(%%esp)\", \"lfence\", X86_FEATURE_XMM2)\n",
    "#define wmb() alternative(\"lock; addl $0,0(%%esp)\", \"sfence\", X86_FEATURE_XMM)\n",
    "#else\n",
    "#define mb() \tasm volatile(\"mfence\":::\"memory\")\n",
    "#define rmb()\tasm volatile(\"lfence\":::\"memory\")\n",
    "#define wmb()\tasm volatile(\"sfence\" ::: \"memory\")\n",
    "#endif\n",
    "```\n",
    "\n",
    "1. If cpu doesn't support `mfence,lfence,sfence`, use `lock` instruction. The LOCK prefix ensures that the CPU has exclusive ownership of the appropriate cache line for the duration of the operation, and provides certain additional ordering guarantees. This may be achieved by asserting a bus lock, but the CPU will avoid this where possible. \n",
    "\n",
    "2. [Lock & memory order](https://stackoverflow.com/questions/60332591/why-is-lock-a-full-barrier-on-x86)\n",
    "\n",
    "3. [缓存一致性MESI](https://cloud.tencent.com/developer/article/1548942)\n",
    "\n",
    "\n",
    "4. Compiler Barriers\n",
    "\n",
    "对编译器的优化我们可以使用compiler barrier，比如大家熟知的\"volatile\"，就可以让编译器生成的代码，每次都从内存重新读取变量的值，而不是用寄存器中暂存的值。因为在多线程环境中，不会被当前线程修改的变量，可能会被其他的线程修改，从内存读才可靠。\n",
    "\n",
    "这就部分解释了上文留的那个问题，即为什么要用READ_ONCE()和WRITE_ONCE()这两个宏，因为atomic_read()和atomic_set()所操作的这个变量，可能会被多核/多线程同时修改，需要避免编译器把它当成一个普通的变量，做出错误的优化。还有一部分原因是，这两个宏可以作为标记，提醒编程人员这里面是一个多核/多线程共享的变量，必要的时候应该加互斥锁来保护。\n",
    "\n",
    "Linux中设置compiler barrier的函数是barrier()，它对应gcc的实现是这样的（定义在include/linux/compiler-gcc.h）：\n",
    "\n",
    "/* The \"volatile\" is due to gcc bugs */\n",
    "#define barrier() __asm__ __volatile__(\"\": : :\"memory\")\n",
    "这是一个内嵌汇编，里是一个空的指令，空的指令怎么发挥作用？\n",
    "\n",
    "它其实利用了末尾clobber list里的\"memory\"，clober list是gcc和gas(GNU Assembler)的接口，用于gas通知gcc它对寄存器和memory的修改情况。\n",
    "\n",
    "这里的\"memory\"就是告知gcc，在汇编代码中，我修改了内存中的内容，之前的C代码块和之后的C代码块看到的内存是不一样的，对内存的访问不能依赖于嵌入汇编之前的C代码块中寄存器的内容，所以乖乖地重新从内存读数据吧。\n",
    "\n",
    "也不知道编译器能不能识别这种伎俩，反正最后它是欣然的被骗了。需要注意的是，barrier()只会对编译器的行为产生约束，它不会生成真正的指令，因此对最终CPU的指令执行没有影响。\n",
    "\n",
    "Linux还提供了一个函数叫smp_mb()，看起来好像是专门用于SMP系统的memory barrier，那它能提供SMP系统中，不同CPU对内存访问顺序的保证吗？不能，SMP系统中，它就等同于mb()，在UP系统中，它会退化为compiler barrier。\n",
    "\n",
    "----------------------------\n",
    "\n",
    "```c\n",
    "#ifdef CONFIG_SMP\n",
    "#define smp_mb()\tmb()\n",
    "#else\t\n",
    "#define smp_mb()\tbarrier()\n",
    "#endif\n",
    "```\n",
    "\n",
    "smp_mb()并不像很多人理解的那样，是mb()的超集(superset)，相反，它只能算mb()的子集(subset)。能用smp_mb()的地方可以用mb()代替，但能用mb()的地方不一定能用smp_mb()代替。\n",
    "\n",
    "即使在多核系统上smp_mb也比mb弱。smp_mb的作用范围局限在CPU cores之间，mb的作用范围包括CPU cores和SoC上其他模块。\n",
    "\n",
    "5. [linux barrier](https://zhuanlan.zhihu.com/p/96001570)\n",
    "\n",
    "6. [barrier and linux kernel](https://community.arm.com/arm-community-blogs/b/architectures-and-processors-blog/posts/memory-access-ordering-part-2---barriers-and-the-linux-kernel)\n",
    "\n",
    "----------------------------\n",
    "\n",
    "```c\n",
    "/* Optimization barrier */\n",
    "/* The \"volatile\" is due to gcc bugs */\n",
    "#define barrier() __asm__ __volatile__(\"\": : :\"memory\")\n",
    "```\n",
    "\n",
    "1. this is the barrier definition. It's a compiler barrier.\n",
    "\n",
    "`volatile` and `memory` both tell the compiler read value from memory not from registers. All memory access operations before the barrier can't be reordered behind it and same as the operations behind it.\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "```c\n",
    "#ifdef CONFIG_X86_PPRO_FENCE\n",
    "#define dma_rmb()\trmb()\n",
    "#else\n",
    "#define dma_rmb()\tbarrier()\n",
    "#endif\n",
    "#define dma_wmb()\tbarrier()\n",
    "\n",
    "#ifdef CONFIG_SMP\n",
    "#define smp_mb()\tmb()\n",
    "#define smp_rmb()\tdma_rmb()\n",
    "#define smp_wmb()\tbarrier()\n",
    "#define smp_store_mb(var, value) do { (void)xchg(&var, value); } while (0)\n",
    "#else /* !SMP */\n",
    "#define smp_mb()\tbarrier()\n",
    "#define smp_rmb()\tbarrier()\n",
    "#define smp_wmb()\tbarrier()\n",
    "#define smp_store_mb(var, value) do { WRITE_ONCE(var, value); barrier(); } while (0)\n",
    "#endif /* SMP */\n",
    "```\n",
    "\n",
    "1. `barrier()` is just a compiler barrier. For UP, compiler barrier is enougth. \n",
    "\n",
    "2. for SMP, `smp_wmb` only need compiler barrier, because for x86, 而在x86中，对于同一CPU执行的load指令后接load指令（L-L），store指令后接store指令（S-S），load指令后接store指令（L-S），都是不能交换指令的执行顺序的，只有store指令后接load指令（S-L）时才可以[注1]。这种memory order被称为TSO(Total Store Order)，俗称strong order。\n",
    "\n",
    "也就是说，`write` 在cpu中不会重排到其他write前面，既然cpu不这么做，我们只要约束compiler不重排就好了\n",
    "\n",
    "3. 对于 rmb和mb，就要用`mfence` 和 `lfence` 来约束cpu的行为\n",
    "\n",
    "-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
