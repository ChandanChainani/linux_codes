{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory zone\n",
    "\n",
    "![zone01](resources/zone01.png)[ref](https://stackoverflow.com/questions/18061218/how-linux-kernel-decide-to-which-memory-zone-to-use)\n",
    "\n",
    "![zone02](resources/zone02.png)\n",
    "![zone03](resources/zone03.png)\n",
    "\n",
    "[x64 mem layout](https://unix.stackexchange.com/questions/509607/how-a-64-bit-process-virtual-address-space-is-divided-in-linux)\n",
    "\n",
    "[canonical address](https://en.wikipedia.org/wiki/X86-64#Virtual_address_space_details)\n",
    "\n",
    "---------------------\n",
    "\n",
    "## linux2.6/include/linux/mmzone.h\n",
    "\n",
    "```c\n",
    "#define ZONE_DMA\t\t0\n",
    "#define ZONE_NORMAL\t\t1\n",
    "#define ZONE_HIGHMEM\t\t2\n",
    "#define MAX_NR_ZONES\t\t3\n",
    "#define GFP_ZONEMASK\t0x03\n",
    "\n",
    "/*\n",
    " * One allocation request operates on a zonelist. A zonelist\n",
    " * is a list of zones, the first one is the 'goal' of the\n",
    " * allocation, the other zones are fallback zones, in decreasing\n",
    " * priority.\n",
    " *\n",
    " * Right now a zonelist takes up less than a cacheline. We never\n",
    " * modify it apart from boot-up, and only a few indices are used,\n",
    " * so despite the zonelist table being relatively big, the cache\n",
    " * footprint of this construct is very small.\n",
    " */\n",
    "struct zonelist {\n",
    "\tstruct zone *zones[MAX_NUMNODES * MAX_NR_ZONES + 1]; // NULL delimited\n",
    "};\n",
    "\n",
    "```\n",
    "1. define some consts\n",
    "\n",
    "```c\n",
    "/*\n",
    " * The pg_data_t structure is used in machines with CONFIG_DISCONTIGMEM\n",
    " * (mostly NUMA machines?) to denote a higher-level memory zone than the\n",
    " * zone denotes.\n",
    " *\n",
    " * On NUMA machines, each NUMA node would have a pg_data_t to describe\n",
    " * it's memory layout.\n",
    " *\n",
    " * Memory statistics and page replacement data structures are maintained on a\n",
    " * per-zone basis.\n",
    " */\n",
    "struct bootmem_data;\n",
    "typedef struct pglist_data {\n",
    "\tstruct zone node_zones[MAX_NR_ZONES];\n",
    "\tstruct zonelist node_zonelists[MAX_NR_ZONES];\n",
    "\tint nr_zones;\n",
    "\tstruct page *node_mem_map;\n",
    "\tunsigned long *valid_addr_bitmap;\n",
    "\tstruct bootmem_data *bdata;\n",
    "\tunsigned long node_start_pfn;\n",
    "\tunsigned long node_present_pages; /* total number of physical pages */\n",
    "\tunsigned long node_spanned_pages; /* total size of physical page\n",
    "\t\t\t\t\t     range, including holes */\n",
    "\tint node_id;\n",
    "\tstruct pglist_data *pgdat_next;\n",
    "\twait_queue_head_t       kswapd_wait;\n",
    "} pg_data_t;\n",
    "\n",
    "#define node_present_pages(nid)\t(NODE_DATA(nid)->node_present_pages)\n",
    "#define node_spanned_pages(nid)\t(NODE_DATA(nid)->node_spanned_pages)\n",
    "\n",
    "```\n",
    "\n",
    "1. NUMA node\n",
    "\n",
    "2. `node_mem_map` array of page descriptors of the node\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linux2.6/include/linux/gfp.h\n",
    "\n",
    "![gfp01](resources/gfp01.png)\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buddy system algorithm\n",
    "\n",
    "![buddy01](resources/buddy01.png)\n",
    "![buddy02](resources/buddy02.png)\n",
    "\n",
    "-----------------\n",
    "\n",
    "## linux2.6/include/linux/mmzone.h\n",
    "\n",
    "```c\n",
    "struct free_area {\n",
    "\tstruct list_head\tfree_list;\n",
    "\tunsigned long\t\t*map;\n",
    "};\n",
    "\n",
    "/*\n",
    "    * free areas of different sizes\n",
    "    */\n",
    "struct free_area\tfree_area[MAX_ORDER];\n",
    "```\n",
    "1. free_area is the buddy list array of different orders.\n",
    "\n",
    "\n",
    "## linux2.6/mm/page_alloc.c\n",
    "\n",
    "### allocate one page\n",
    "\n",
    "```c\n",
    "/* \n",
    " * Do the hard work of removing an element from the buddy allocator.\n",
    " * Call me with the zone->lock already held.\n",
    " */\n",
    "static struct page *__rmqueue(struct zone *zone, unsigned int order)\n",
    "{\n",
    "\tstruct free_area * area;\n",
    "\tunsigned int current_order;\n",
    "\tstruct page *page;\n",
    "\tunsigned int index;\n",
    "\n",
    "\tfor (current_order = order; current_order < MAX_ORDER; ++current_order) {\n",
    "\t\tarea = zone->free_area + current_order;\n",
    "\t\tif (list_empty(&area->free_list))\n",
    "\t\t\tcontinue;\n",
    "\n",
    "\t\tpage = list_entry(area->free_list.next, struct page, list);\n",
    "\t\tlist_del(&page->list);\n",
    "\t\tindex = page - zone->zone_mem_map;\n",
    "\t\tif (current_order != MAX_ORDER-1)\n",
    "\t\t\tMARK_USED(index, current_order, area);\n",
    "\t\tzone->free_pages -= 1UL << order;\n",
    "\t\treturn expand(zone, page, index, order, current_order, area);\n",
    "\t}\n",
    "\n",
    "\treturn NULL;\n",
    "}\n",
    "\n",
    "static inline struct page *\n",
    "expand(struct zone *zone, struct page *page,\n",
    "\t unsigned long index, int low, int high, struct free_area *area)\n",
    "{\n",
    "\tunsigned long size = 1 << high;\n",
    "\n",
    "\twhile (high > low) {\n",
    "\t\tBUG_ON(bad_range(zone, page));\n",
    "\t\tarea--;\n",
    "\t\thigh--;\n",
    "\t\tsize >>= 1;\n",
    "\t\tlist_add(&page->list, &area->free_list);\n",
    "\t\tMARK_USED(index, high, area);\n",
    "\t\tindex += size;\n",
    "\t\tpage += size;\n",
    "\t}\n",
    "\treturn page;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "1. `__rmqueue` 从 `free_area` 里面取出大小合适的block\n",
    "\n",
    "2. `expand` 裁剪block。把block最后一段>=order 的内存返回，其他的放入到对应的list里面\n",
    "\n",
    "-----------------------\n",
    "\n",
    "### free one page\n",
    "\n",
    "```c\n",
    "/*\n",
    " * Freeing function for a buddy system allocator.\n",
    " *\n",
    " * The concept of a buddy system is to maintain direct-mapped table\n",
    " * (containing bit values) for memory blocks of various \"orders\".\n",
    " * The bottom level table contains the map for the smallest allocatable\n",
    " * units of memory (here, pages), and each level above it describes\n",
    " * pairs of units from the levels below, hence, \"buddies\".\n",
    " * At a high level, all that happens here is marking the table entry\n",
    " * at the bottom level available, and propagating the changes upward\n",
    " * as necessary, plus some accounting needed to play nicely with other\n",
    " * parts of the VM system.\n",
    " * At each level, we keep one bit for each pair of blocks, which\n",
    " * is set to 1 iff only one of the pair is allocated.  So when we\n",
    " * are allocating or freeing one, we can derive the state of the\n",
    " * other.  That is, if we allocate a small block, and both were   \n",
    " * free, the remainder of the region must be split into blocks.   \n",
    " * If a block is freed, and its buddy is also free, then this\n",
    " * triggers coalescing into a block of larger size.            \n",
    " *\n",
    " * -- wli\n",
    " */\n",
    "\n",
    "static inline void __free_pages_bulk (struct page *page, struct page *base,\n",
    "\t\tstruct zone *zone, struct free_area *area, unsigned long mask,\n",
    "\t\tunsigned int order)\n",
    "{\n",
    "\tunsigned long page_idx, index;\n",
    "\n",
    "\tif (order)\n",
    "\t\tdestroy_compound_page(page, order);\n",
    "\tpage_idx = page - base;\n",
    "\tif (page_idx & ~mask)\n",
    "\t\tBUG();\n",
    "\tindex = page_idx >> (1 + order);\n",
    "\n",
    "\tzone->free_pages -= mask;\n",
    "\twhile (mask + (1 << (MAX_ORDER-1))) {\n",
    "\t\tstruct page *buddy1, *buddy2;\n",
    "\n",
    "\t\tBUG_ON(area >= zone->free_area + MAX_ORDER);\n",
    "\t\tif (!__test_and_change_bit(index, area->map))\n",
    "\t\t\t/*\n",
    "\t\t\t * the buddy page is still allocated.\n",
    "\t\t\t */\n",
    "\t\t\tbreak;\n",
    "\t\t/*\n",
    "\t\t * Move the buddy up one level.\n",
    "\t\t * This code is taking advantage of the identity:\n",
    "\t\t * \t-mask = 1+~mask\n",
    "\t\t */\n",
    "\t\tbuddy1 = base + (page_idx ^ -mask);\n",
    "\t\tbuddy2 = base + page_idx;\n",
    "\t\tBUG_ON(bad_range(zone, buddy1));\n",
    "\t\tBUG_ON(bad_range(zone, buddy2));\n",
    "\t\tlist_del(&buddy1->list);\n",
    "\t\tmask <<= 1;\n",
    "\t\tarea++;\n",
    "\t\tindex >>= 1;\n",
    "\t\tpage_idx &= mask;\n",
    "\t}\n",
    "\tlist_add(&(base + page_idx)->list, &area->free_list);\n",
    "}\n",
    "\n",
    "\n",
    "/*\n",
    " * Frees a list of pages. \n",
    " * Assumes all pages on list are in same zone, and of same order.\n",
    " * count is the number of pages to free, or 0 for all on the list.\n",
    " *\n",
    " * If the zone was previously in an \"all pages pinned\" state then look to\n",
    " * see if this freeing clears that state.\n",
    " *\n",
    " * And clear the zone's pages_scanned counter, to hold off the \"all pages are\n",
    " * pinned\" detection logic.\n",
    " */\n",
    "static int\n",
    "free_pages_bulk(struct zone *zone, int count,\n",
    "\t\tstruct list_head *list, unsigned int order)\n",
    "{\n",
    "\tunsigned long mask, flags;\n",
    "\tstruct free_area *area;\n",
    "\tstruct page *base, *page = NULL;\n",
    "\tint ret = 0;\n",
    "\n",
    "\tmask = (~0UL) << order;\n",
    "\tbase = zone->zone_mem_map;\n",
    "\tarea = zone->free_area + order;\n",
    "\tspin_lock_irqsave(&zone->lock, flags);\n",
    "\tzone->all_unreclaimable = 0;\n",
    "\tzone->pages_scanned = 0;\n",
    "\twhile (!list_empty(list) && count--) {\n",
    "\t\tpage = list_entry(list->prev, struct page, list);\n",
    "\t\t/* have to delete it as __free_pages_bulk list manipulates */\n",
    "\t\tlist_del(&page->list);\n",
    "\t\t__free_pages_bulk(page, base, zone, area, mask, order);\n",
    "\t\tret++;\n",
    "\t}\n",
    "\tspin_unlock_irqrestore(&zone->lock, flags);\n",
    "\treturn ret;\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linux2.6/include/linux/mm.h\n",
    "\n",
    "```c\n",
    "/*\n",
    " * Each physical page in the system has a struct page associated with\n",
    " * it to keep track of whatever it is we are using the page for at the\n",
    " * moment. Note that we have no way to track which tasks are using\n",
    " * a page.\n",
    " *\n",
    " * Try to keep the most commonly accessed fields in single cache lines\n",
    " * here (16 bytes or greater).  This ordering should be particularly\n",
    " * beneficial on 32-bit processors.\n",
    " *\n",
    " * The first line is data used in page cache lookup, the second line\n",
    " * is used for linear searches (eg. clock algorithm scans). \n",
    " *\n",
    " * TODO: make this structure smaller, it could be as small as 32 bytes.\n",
    " */\n",
    "struct page {\n",
    "\tunsigned long flags;\t\t/* atomic flags, some possibly\n",
    "\t\t\t\t\t   updated asynchronously */\n",
    "\tatomic_t count;\t\t\t/* Usage count, see below. */\n",
    "\tstruct list_head list;\t\t/* ->mapping has some page lists. */\n",
    "\tstruct address_space *mapping;\t/* The inode (or ...) we belong to. */\n",
    "\tunsigned long index;\t\t/* Our offset within mapping. */\n",
    "\tstruct list_head lru;\t\t/* Pageout list, eg. active_list;\n",
    "\t\t\t\t\t   protected by zone->lru_lock !! */\n",
    "\tunion {\n",
    "\t\tstruct pte_chain *chain;/* Reverse pte mapping pointer.\n",
    "\t\t\t\t\t * protected by PG_chainlock */\n",
    "\t\tpte_addr_t direct;\n",
    "\t} pte;\n",
    "\tunsigned long private;\t\t/* mapping-private opaque data */\n",
    "\n",
    "\t/*\n",
    "\t * On machines where all RAM is mapped into kernel address space,\n",
    "\t * we can simply calculate the virtual address. On machines with\n",
    "\t * highmem some memory is mapped into kernel virtual memory\n",
    "\t * dynamically, so we need a place to store that address.\n",
    "\t * Note that this field could be 16 bits on x86 ... ;)\n",
    "\t *\n",
    "\t * Architectures with slow multiplication can define\n",
    "\t * WANT_PAGE_VIRTUAL in asm/page.h\n",
    "\t */\n",
    "#if defined(WANT_PAGE_VIRTUAL)\n",
    "\tvoid *virtual;\t\t\t/* Kernel virtual address (NULL if\n",
    "\t\t\t\t\t   not kmapped, ie. highmem) */\n",
    "#endif /* WANT_PAGE_VIRTUAL */\n",
    "};\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d47d1382e92bbaf84c50276baa079056532326c20bdaac4b09430c41eda0c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
